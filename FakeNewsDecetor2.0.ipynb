{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bad51c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f32311ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake = pd.read_csv(\"fake.csv\")\n",
    "data_true = pd.read_csv(\"True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a4b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding class labels\n",
    "data_fake[\"class\"] = 0\n",
    "data_true[\"class\"] = 1\n",
    "\n",
    "# Removing last 10 entries for manual testing\n",
    "data_fake_manual_testing = data_fake.tail(10)\n",
    "data_true_manual_testing = data_true.tail(10)\n",
    "data_fake = data_fake.iloc[:-10]\n",
    "data_true = data_true.iloc[:-10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9363e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the datasets\n",
    "data_merge = pd.concat([data_fake, data_true], axis=0)\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "data = data_merge.drop([\"title\", \"subject\", \"date\"], axis=1)\n",
    "\n",
    "# Shuffling the data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05114103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordopt(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\", \" \", text)\n",
    "    text = re.sub(\"https?://\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(\"<.*?>+\", \"\", text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(\"\\n\", \"\", text)\n",
    "    text = re.sub(\"\\w*\\d\\w*\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "246b230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying text preprocessing\n",
    "data['text'] = data['text'].apply(wordopt)\n",
    "\n",
    "# Splitting the data\n",
    "x = data['text']\n",
    "y = data['class']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc81b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorization = TfidfVectorizer()\n",
    "xv_train = vectorization.fit_transform(x_train)\n",
    "xv_test = vectorization.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52229058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9866310160427807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5886\n",
      "           1       0.98      0.99      0.99      5334\n",
      "\n",
      "    accuracy                           0.99     11220\n",
      "   macro avg       0.99      0.99      0.99     11220\n",
      "weighted avg       0.99      0.99      0.99     11220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(xv_train, y_train)\n",
    "pred_lr = LR.predict(xv_test)\n",
    "print(\"Logistic Regression Accuracy:\", LR.score(xv_test, y_test))\n",
    "print(classification_report(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3438604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9961675579322639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5886\n",
      "           1       1.00      1.00      1.00      5334\n",
      "\n",
      "    accuracy                           1.00     11220\n",
      "   macro avg       1.00      1.00      1.00     11220\n",
      "weighted avg       1.00      1.00      1.00     11220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(xv_train, y_train)\n",
    "pred_dt = DT.predict(xv_test)\n",
    "print(\"Decision Tree Accuracy:\", DT.score(xv_test, y_test))\n",
    "print(classification_report(y_test, pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b1d47cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.9940285204991087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      5886\n",
      "           1       0.99      1.00      0.99      5334\n",
      "\n",
      "    accuracy                           0.99     11220\n",
      "   macro avg       0.99      0.99      0.99     11220\n",
      "weighted avg       0.99      0.99      0.99     11220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB = GradientBoostingClassifier(random_state=0)\n",
    "GB.fit(xv_train, y_train)\n",
    "pred_gb = GB.predict(xv_test)\n",
    "print(\"Gradient Boosting Accuracy:\", GB.score(xv_test, y_test))\n",
    "print(classification_report(y_test, pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a81e5a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9875222816399287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5886\n",
      "           1       0.99      0.99      0.99      5334\n",
      "\n",
      "    accuracy                           0.99     11220\n",
      "   macro avg       0.99      0.99      0.99     11220\n",
      "weighted avg       0.99      0.99      0.99     11220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(random_state=0)\n",
    "RF.fit(xv_train, y_train)\n",
    "pred_rf = RF.predict(xv_test)\n",
    "print(\"Random Forest Accuracy:\", RF.score(xv_test, y_test))\n",
    "print(classification_report(y_test, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM.fit(xv_train, y_train)\n",
    "pred_svm = SVM.predict(xv_test)\n",
    "print(\"Support Vector Machine Accuracy:\", SVM.score(xv_test, y_test))\n",
    "print(classification_report(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82742865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB = MultinomialNB()\n",
    "NB.fit(xv_train, y_train)\n",
    "pred_nb = NB.predict(xv_test)\n",
    "print(\"Naive Bayes Accuracy:\", NB.score(xv_test, y_test))\n",
    "print(classification_report(y_test, pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bacdca96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Neural Network using Keras\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# Neural Network using Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b5878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and padding\n",
    "max_words = 5000\n",
    "max_len = 500\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_train_nn = pad_sequences(train_sequences, maxlen=max_len)\n",
    "x_test_nn = pad_sequences(test_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199269fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_len,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d3ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "history = model.fit(x_train_nn, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=2)\n",
    "\n",
    "# Evaluating the model\n",
    "loss, accuracy = model.evaluate(x_test_nn, y_test)\n",
    "print(\"Neural Network Accuracy:\", accuracy)\n",
    "pred_nn = (model.predict(x_test_nn) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test, pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f70f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual testing function\n",
    "def output_label(n):\n",
    "    return 'Fake News' if n == 0 else 'True News'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6692fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_testing(news):\n",
    "    testing_news = {\"text\": [news]}\n",
    "    new_def_test = pd.DataFrame(testing_news)\n",
    "    new_def_test['text'] = new_def_test['text'].apply(wordopt)\n",
    "    new_x_test = new_def_test['text']\n",
    "    new_xv_test = vectorization.transform(new_x_test)\n",
    "    \n",
    "    pred_LR = LR.predict(new_xv_test)\n",
    "    pred_DT = DT.predict(new_xv_test)\n",
    "    pred_GB = GB.predict(new_xv_test)\n",
    "    pred_RF = RF.predict(new_xv_test)\n",
    "    pred_SVM = SVM.predict(new_xv_test)\n",
    "    pred_NB = NB.predict(new_xv_test)\n",
    "    \n",
    "    new_seq_test = tokenizer.texts_to_sequences(new_x_test)\n",
    "    new_x_test_nn = pad_sequences(new_seq_test, maxlen=max_len)\n",
    "    pred_NN = (model.predict(new_x_test_nn) > 0.5).astype(\"int32\")\n",
    "    \n",
    "    print(\"\\n\\nLR prediction: {} \\nDT Prediction: {} \\nGBC prediction: {} \\nRFC prediction: {} \\nSVM prediction: {} \\nNB prediction: {} \\nNN prediction: {}\".format(\n",
    "        output_label(pred_LR[0]),\n",
    "        output_label(pred_DT[0]),\n",
    "        output_label(pred_GB[0]),\n",
    "        output_label(pred_RF[0]),\n",
    "        output_label(pred_SVM[0]),\n",
    "        output_label(pred_NB[0]),\n",
    "        output_label(pred_NN[0])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacfa39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual testing\n",
    "news = input(\"Enter news text: \")\n",
    "manual_testing(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a546b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91c8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
